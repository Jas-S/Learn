## 性能测试概述

### 为什么做性能测试

#### 业务需求

* 电商双11活动/微信春晚抢红包/12306春运订票
* 当前服务器配置是否支持20000人同时使用
* 技术选型，如编程语言选择Java？Python？GO？

### :triangular_flag_on_post:性能测试的概念

#### 什么是性能？

就是软件质量属性中的“效率”特性。
效率特性：

* 时间特性：指系统处理用户请求的相应时间
* 资源特性：指系统在运行过程中，系统资源的消耗情况
  * CPU
  * 内存
  * 磁盘IO
  
#### 什么是性能测试？

概念：使用自动化工具，模拟不同的场景，对软件各项性能指标进行测试和评估的过程。

> 1. 后台处理程序的性能（代码性能）
> 2. 中间件，数据库，架构设计等是否存在瓶颈
> 3. 服务器资源消耗（CPU，内存，磁盘，网络）
>
> 中间件：是提供系统软件和应用软件之间连接的软件。如：Tomcat，Apache等

### :triangular_flag_on_post:性能测试的目的

1. 评估当前系统能力。

> 例如：
>
>* 验收第三方提供的软件
>* 获取关键的性能指标，与其它类似产品进行比较

2. 寻找性能瓶颈，优化性能

3. 评估软件是否能够满足未来的需要

### 性能测试和功能测试

#### 不同

* 功能测试：验证软件系统操作功能是否符合产品功能需求规格，主要焦点在功能（正向，逆向）；
* 性能测试：验证软件系统是否满足业务需求场景，主要焦点是业务场景的满足（时间，资源）。

#### 关系

* 功能测试和性能测试是相辅相成的，对于一款优秀的软件产品来讲，它们是不可缺少的2个重要测试环节。  
注意：一般项目中，先通过功能测试后再进行性能测试。

## :triangular_flag_on_post:性能测试策略

### 1.基准测试

* 狭义：即单用户测试，测试环境确定以后，对业务模型中的重要业务做单独的测试，获取单用户运行时的各项性能指标。（进行基础的数据采集）
* 广义：是一种测量和评估软件性能指标的活动。你可以在某个时刻通过基准测试建立一个已知的性能水平（称为基准线），当系统的软硬件环境发生变化之后再进行一次基准测试以确定那些变化对性能的影响。

基准测试数据用途：

1. 为多用户并发测试和综合场景测试等性能分析提供参考依据
2. 识别系统或环境的配置变更对性能响应带来的影响
3. 为系统优化前后的性能提升/下降提供参考指标

### 2.负载测试

通过逐步增加系统负载，测试系统性能的变化，并最终确定在满足系统的性能指标情况下，系统所能承受的最大负载量的测试。
通过负载测试，一般能找到系统的最优负载和最大负载。
最大负载一般项目组内部知晓，不会对外公布。
普通用户看到的系统最大负载能力，一般都是测试得到的最优负载。
负载：是指向服务器发送的请求数量，请求越多，负载越高.
注意：负载测试关注的重点是逐步增加压力

### 3.稳定性测试

在服务器稳定运行（用户正常的业务负载下）的情况下进行长时间测试，并最终保证服务器能满足线上业务需求。时长一般为1天，1周等。

### 4.其他

> 性能测试中，测试策略其实有很多种，但是掌握基础用法后，其它不同名称的测试策略只是基础用法的一个变形用法。  

* 并发测试：在极短时间内，发送多个请求，来验证服务器对并发的处理能力。如：抢红包，秒杀活动等。
* 压力测试：在强负载（大数据量，大量并发用户等）下的测试，查看应用系统在峰值使用情况下操作行为，从而有效的发现系统的某项功能隐患，系统是否具有良好的容错能力和可恢复能力。压力测试分为高负载下的长时间（如24小时以上）的稳定性压力测试和极限负载情况下导致系统崩溃的破坏性压力测试。
* 容量测试：关注软件的极限压力下的各个极限参数值，例如：最大QPS，最大链接数，最大并发数，最多数据条数等。

## 性能测试指标

### :triangular_flag_on_post:响应时间

指用户从客户端发起一个请求开始，到客户端接收到从服务器端返回的结果，整个过程所耗费的全部时间。
响应时间 = 网络时间 + 应用程序处理时间

### :triangular_flag_on_post:并发数

并发访问的用户数
扩展：

* 系统用户数：系统注册的总用户数
* 在线用户数：某段时间内访问系统的用户数，这些用户并不一定同时向系统提交请求
* 并发用户数：某一物理时刻同时向系统提交请求的用户数

### :triangular_flag_on_post:吞吐量

吞吐量（Throughput）指的是单位时间内处理的客户端请求数量，直接体现软件系统的性能承载能力。

> 注意：
>
> 1. 从业务角度来看，吞吐量也可以用“业务数/小时”，“业务数/天”，“访问人数/天”，“页面访问量/天”来衡量
> 2. 从网络角度来看，还可以用“字节数/小时”，“字节数/天”等来衡量网络的流量
> 3. 从技术指标来看，可以用每秒事务数（TPS）和每秒查询数（QPS）来衡量服务器具体性能处理能力  
> ※ QPS >= TPS

### 点击数

是衡量Web服务器处理能力的一个重要指标。  
提示：

1. 点击数不是通常认为的访问一个页面就是1次点击，而是该页面包含的元素（图片，连接）向服务器发出的请求数量。
2. 通常我们也用每秒点击次数（Hits per Second）指标来衡量Web服务器的处理能力。

> 注意：只有web项目才有此指标。

### 错误率

指系统在负载情况下，失败业务的概率。错误率=（失败业务数/业务总数）*100%。  
提示：

1. 不同系统对错误率要求不同，但一般不超过千分之五；
2. 稳定性较好的系统，其错误率应该由超时引起，即为超时率。

### :triangular_flag_on_post:资源使用率

是指系统各种资源的使用情况，一般用“资源的使用量/总的资源可用量*100%”形成资源利用率的数据。

提示：通常，没有特殊需求的话  
1). 建议CPU不高于80%（±5）  
2). 内存不高于80%  
3). 磁盘不高于90%  
4). 网络不高于80%

## :triangular_flag_on_post:性能测试流程

### 1.性能需求分析

性能需求分析是整个性能测试工作开展的基础，性能需求分析做的好不好直接影响到性能测试的结果。
性能需求分析的目标：

1. 熟悉被测系统

* 熟悉被测系统的业务功能
* 熟悉被测系统的技术架构

2. 明确性能测试内容

* 从业务角度明确测试内容
  * 确定关键业务。即：用户使用频率较高的业务功能

* 从技术角度明确测试内容
  * 通常逻辑复杂度较高的业务也是CPU密集运算较大的地方，考量服务器CPU在预定性能指标下是否达标
  * 通常数据量较大的业务很占用系统内存，考量服务器内存在预定性能指标下是否达标

3. 明确性能测试策略

* 负载测试
* 稳定性测试
* 并发测试

4. 明确性能测试的指标

* 无明确需求指标
  * 通过查找相关资料，和类似的系统对比，以及对未来流量的预估，确定性能测试需求的指标

* 有明确的需求指标
  * 例如，类似如下指标
    * 下订单业务并发20个用户
    * 平均响应时间不超过3s
    * 事务成功率为100%
    * CPU使用率小于等于85%
  * 只需要根据执行分析结果与预期指标做对比，如果有不满足的，就需要分析问题所在

### 2.性能测试计划和方案

### 3.性能测试用例

### 4.性能测试脚本编写/录制

### 5.建立测试环境

### 6.执行测试脚本

### 7.性能测试监控

### 8.性能分析和调优

### 9.性能测试报告总结

## 性能测试工具介绍
